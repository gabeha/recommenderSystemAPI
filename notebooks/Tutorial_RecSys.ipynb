{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Recommender System\n",
    "\n",
    "## Introduction\n",
    "This notebook provides an overview of the recommender system we have built for UCM. It includes key aspects to help you understand the system's functionality and workflow. We'll begin with how to call the system and then delve into the details of each component.\n",
    "\n",
    "Note: We are not Software Engineers, so the structure might not be the best. We are open to suggestions and improvements.\n",
    "\n",
    "Before starting, it's necessary to install the system's requirements. These are listed in the `requirements.txt` file. To install them, run the following command in your terminal:\n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "\n",
    "Additionally, when you run the system for the first time, some transformer models will be downloaded. This will take some time in the first run. Moreover, we use MongoDB for the system. You need to have MongoDB installed on your system. You can download MongoDB from [here](https://www.mongodb.com/try/download/community).\n",
    "\n",
    "## Table of Contents:\n",
    "1. [Initialization and Recommender System Structure](#Initialization-and-Recommender-System-Structure)\n",
    "2. [Keyword Similarity](#Keyword-Similarity)\n",
    "3. [Bloom's Taxonomy](#Bloom's-Taxonomy)\n",
    "4. [Explanation with Generative LLM](#Explanation-with-Generative-LLM)\n",
    "5. [Planner (Integer Linear Programming)](#Planner-(Integer-Linear-Programming))\n",
    "6. [Warning System](#Warning-System)\n",
    "7. [Collaborative Filtering](#Collaborative-Filtering)\n",
    "8. [Knowledge Graph](#Knowledge-Graph)\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48ed2a093f30ccdb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialization and Recommender System Structure:\n",
    "\n",
    "The file `instances/recommender_instances.py` contains the initialization of the recommender system. Here, we import all the components that are required for the system. The components are initialized once and then used throughout the system. The system's structure is kept as modular as possible. This modularity aids in the easy integration of new components into the system and in its maintenance.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42da83684d684bbc"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os\n",
    "# First we change the directory to the root directory of the project. Where we usually run the app.py file.\n",
    "os.chdir(os.getcwd().replace(\"\\\\notebooks\", \"\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:01:41.094322800Z",
     "start_time": "2023-12-12T15:01:40.952834900Z"
    }
   },
   "id": "95a857797e8e0f5b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CourseBasedRecSys config: \n",
      "model_name: all-MiniLM-L12-v2\n",
      "seed_help: True\n",
      "domain_adapt: True\n",
      "zero_adapt: True\n",
      "seed_type: title\n",
      "domain_type: title\n",
      "zero_type: title\n",
      "adaptive_thr: 0.0\n",
      "minimal_similarity_zeroshot: 0.8\n",
      "score_alg: sum\n",
      "distance: cos\n",
      "backend: keyBert\n",
      "scaler: True\n",
      "sent_splitter: False\n",
      "precomputed_course: True\n",
      "\n",
      "Loading warning models: \n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/144 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c302d494acf740dfa75f7b18ebf9380d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning model loaded successfully!\n",
      "\n",
      "RecSys settings: \n",
      "Validate_input: True \n",
      "Keyword_based: <rec_sys_uni.rec_systems.keyword_based_sys.keyword_based.KeywordBased object at 0x000001DF65037D00> \n",
      "Bloom_based: <rec_sys_uni.rec_systems.bloom_based_sys.bloom_based.BloomBased object at 0x000001E0823BD600> \n",
      "Explanation: <rec_sys_uni.rec_systems.llm_explanation.LLM.LLM object at 0x000001E08229F610> \n",
      "Warning_model: <rec_sys_uni.rec_systems.warning_model.warning_model.WarningModel object at 0x000001E0823BD660> \n",
      "Planner: NoneTop_n: 7 \n"
     ]
    },
    {
     "data": {
      "text/plain": "<rec_sys_uni._helpers_rec_sys.StudentNode at 0x1df65037700>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is example code for the initialization of the system.\n",
    "from instances.recommender_instances import rs\n",
    "\n",
    "# Now with the rs object we can call the components that we need.\n",
    "input = { # Example of the input that we need for the system. Also, this is the input that we get from the front-end.\n",
    "    \"keywords\": {\n",
    "        \"physics\": 1.0,\n",
    "        \"maths\": 1.0,\n",
    "        \"statistics\": 1.0,\n",
    "        \"ai\": 1.0,\n",
    "        \"computer science\": 1.0,\n",
    "        \"chem\": 1.0,\n",
    "    },\n",
    "    \"blooms\": {'create': 0.0,\n",
    "               'understand': 0.0,\n",
    "               'apply': 0.0,\n",
    "               'analyze': 0.0,\n",
    "               'evaluate': 0.0,\n",
    "               'remember': 0.0}\n",
    "}\n",
    "student_node = rs.get_recommendation(input) # This will return the recommendations for the input as a Student Node object.\n",
    "student_node"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:24:33.096100300Z",
     "start_time": "2023-12-12T15:24:27.221581200Z"
    }
   },
   "id": "422acd1016852f38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `StudentNode` object contains all information about the student. It is a class that we have created to keep the information about the student. It contains the following attributes:\n",
    "\n",
    "1. **results**: contains results from the recommender system components.\n",
    "2. **student_input**: contains keywords and Bloom's taxonomy of the student input.\n",
    "3. **course_data**: currently we are using system course data, but later on, the front-end should send the course list for which we need to compute recommendation.\n",
    "4. **student_data**: contains all courses which the student took.\n",
    "5. **id**: unique Student ID, which was assigned by MongoDB.\n",
    "\n",
    "The `StudentNode` object is saved in the MongoDB database. We use the `id` attribute as the unique identifier for the student. We use the `id` attribute to retrieve the `StudentNode` object from the database. It helps call other components of the system independently without sending unnecessary information to the front-end.\n",
    "\n",
    "Let's take a look at each component of the student node at detail.\n",
    "\n",
    "### 1. Results:\n",
    "`results`: A dictionary of recommended courses. For example:\n",
    "\n",
    "- `recommended_courses`: A dictionary where each key is a `course_id` (String) and the value is another dictionary with the following keys:\n",
    "  - `score`: A float representing the total score of each model.\n",
    "  - `period`: A list of integers or a list of lists of integers. For example, `[1, 4]` or `[[1, 2, 3], [4, 5, 6]]` or `[[1,2]]`.\n",
    "  - `warning`: A boolean value.\n",
    "  - `warning_recommendation`: A list of warning recommendations.\n",
    "  - `keywords`: A dictionary of scores for each keyword (only present after applying the CourseBased model).\n",
    "  - `blooms`: A dictionary of scores for each bloom (only present after applying the BloomBased model).\n",
    "\n",
    "- `sorted_recommended_courses`: A list of courses, which are included to the structured recommendation, where each course is a dictionary with the following keys:\n",
    "  - `course_code`: A string.\n",
    "  - `course_name`: A string.\n",
    "  - `warning`: A boolean value.\n",
    "  - `warning_recommendation`: A list of warning recommendations.\n",
    "  - `keywords`: A dictionary where each key is a keyword (String) and the value is a weight (float).\n",
    "  - `blooms`: A dictionary where each key is a bloom (String) and the value is a weight (float).\n",
    "  - `score`: A float.\n",
    "\n",
    "- `structured_recommendation`: A dictionary with the following structure:\n",
    "  - `semester_1`: A dictionary with the following keys:\n",
    "    - `period_1`: A list of `course_id` (String), the length of the list is less than or equal to `top_n`.\n",
    "    - `period_2`: A list of `course_id` (String), the length of the list is less than or equal to `top_n`.\n",
    "  - `semester_2`: A dictionary with the following keys:\n",
    "    - `period_4`: A list of `course_id` (String), the length of the list is less than or equal to `top_n`.\n",
    "    - `period_5`: A list of `course_id` (String), the length of the list is less than or equal to `top_n`.\n",
    "\n",
    "Note: If you apply the `sort_by_periods` function, you will have `structured_recommendation` and `sorted_recommended_courses` keys in the results.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f4a928bb13d328a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['recommended_courses', 'sorted_recommended_courses', 'structured_recommendation'])\n",
      "Number of courses: 149\n",
      "dict_keys(['course_code', 'course_name', 'warning', 'warning_recommendation', 'keywords', 'score'])\n",
      "dict_keys(['semester_1', 'semester_2'])\n",
      "dict_keys(['period_1', 'period_2'])\n",
      "dict_keys(['course_code', 'course_name', 'warning', 'warning_recommendation'])\n"
     ]
    }
   ],
   "source": [
    "print(student_node.results.keys())\n",
    "print(\"Number of courses: \" + str(len(student_node.results[\"recommended_courses\"].keys())))\n",
    "print(student_node.results[\"sorted_recommended_courses\"][0].keys())\n",
    "print(student_node.results[\"structured_recommendation\"].keys())\n",
    "print(student_node.results[\"structured_recommendation\"][\"semester_1\"].keys())\n",
    "print(student_node.results[\"structured_recommendation\"][\"semester_1\"][\"period_1\"][0].keys())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:26:07.125045900Z",
     "start_time": "2023-12-12T15:26:06.966027300Z"
    }
   },
   "id": "ae4cf5bdd3ad52f3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Student Input:\n",
    "`student_input`: A dictionary that contains the student's input. For example:\n",
    "\n",
    "- `keywords`: A dictionary where each key is a keyword (String) and the value is a weight (float).\n",
    "- `blooms`: A dictionary where each key is a bloom (String) and the value is a weight (float).\n",
    "- `semester`: A float representing the semester.\n",
    "\n",
    "Example of `student_input`:\n",
    "\n",
    "```python\n",
    "student_input = {\n",
    "    \"keywords\": {\n",
    "        \"python\": 0.5,\n",
    "        \"data science\": 0.2\n",
    "    },\n",
    "    \"blooms\": {\n",
    "        \"create\": 0.5,\n",
    "        \"understand\": 0.75,\n",
    "        \"apply\": 0.25,\n",
    "        \"analyze\": 0.5,\n",
    "        \"evaluate\": 0.0,\n",
    "        \"remember\": 1.0\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### 3. Course Data:\n",
    "`course_data`: A dictionary where each key is a `course_id` (String) and the value is another dictionary with the following keys:\n",
    "\n",
    "- `course_name`: A string representing the name of the course. For example, \"Philosophy of Science\".\n",
    "- `period`: A list of integers or a list of lists of integers. For example, `[1, 4]` or `[[1, 2, 3], [4, 5, 6]]` or `[[1,2]]`.\n",
    "- `level`: An integer representing the level of the course. For example, 1, 2, or 3.\n",
    "- `prerequisites`: A list of course IDs (Strings) that are prerequisites for the course. For example, `[\"COR1001\", \"COR1002\"]`.\n",
    "- `description`: A string providing a description of the course. For example, \"This course is about ...\".\n",
    "- `ilos`: A list of strings representing the Intended Learning Outcomes (ILOs) of the course. For example, [\"Be able to apply the scientific method to a given problem\", \"Be able to explain the difference between science and pseudoscience\"].\n",
    "\n",
    "Example of `course_data`:\n",
    "\n",
    "```python\n",
    "course_data = {\n",
    "    \"COR1001\": {\n",
    "        \"course_name\": \"Philosophy of Science\",\n",
    "        \"period\": [1, 4],\n",
    "        \"level\": 1,\n",
    "        \"prerequisites\": [\"COR1002\"],\n",
    "        \"description\": \"This course is about ...\",\n",
    "        \"ilos\": [\n",
    "            \"Be able to apply the scientific method to a given problem\",\n",
    "            \"Be able to explain the difference between science and pseudoscience\"\n",
    "        ]\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "Note: We are using the `course_data` from the system. However, later on, the front-end should send the course list for which we need to compute recommendation.\n",
    "\n",
    "### 4. Student Data:\n",
    "`student_data`: A dictionary that contains the student's data. For example:\n",
    "\n",
    "- `courses_taken`: A dictionary where each key is a `course_id` (String) and the value is another dictionary with the following keys:\n",
    "  - `passed`: A boolean value indicating whether the student passed the course.\n",
    "  - `grade`: A float representing the grade the student received in the course.\n",
    "  - `period`: An integer or a list of two integers representing the period(s) when the course was taken.\n",
    "  - `year`: An integer representing the year when the course was taken.\n",
    "\n",
    "Example of `student_data`:\n",
    "\n",
    "```python\n",
    "student_data = {\n",
    "    \"courses_taken\": {\n",
    "        \"COR1001\": {\n",
    "            \"passed\": True,\n",
    "            \"grade\": 3.5,\n",
    "            \"period\": [1, 2],\n",
    "            \"year\": 2022\n",
    "        },\n",
    "        ...\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Note: We are using the `student_data` from the system. However, later on, the front-end should send the student's data along with student ID, which was provided by Maastricht University.\n",
    "\n",
    "### Usage of MongoDB:\n",
    "\n",
    "We use MongoDB to store the `StudentNode` object. We use the `id` attribute to retrieve the `StudentNode` object from the database. We show an example of how to use MongoDB to retrieve the `StudentNode` object in the json format.\n",
    "\n",
    "Local server: `mongodb://localhost:27017/`\n",
    "\n",
    "In the RecSys a.k.a `rs` object, we have a `db` attribute which is the database that we are using. We use a `RecSys` database. We store the `StudentNode` object in the `student_results` collection. We use the `id` attribute as the unique identifier for the student's session. \n",
    "\n",
    "Note: Every time, when student input is sent to the system, we create a new `StudentNode` object and store it in the database.\n",
    "\n",
    "Example: How to use the `id` attribute to retrieve the `StudentNode` object as json from the database."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fca1aa25a0c88f26"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65787b31d0727440ea3d5d6e\n"
     ]
    }
   ],
   "source": [
    "# This is an example of id that we get from MongoDB.\n",
    "print(student_node.id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:26:08.085586600Z",
     "start_time": "2023-12-12T15:26:07.900558600Z"
    }
   },
   "id": "a8861834943f7790"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['_id', 'student_id', 'student_input', 'course_data', 'student_data', 'results', 'time'])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bson.objectid import ObjectId\n",
    "# First we need to get the database from the rs object.\n",
    "db = rs.db\n",
    "\n",
    "# Then we get the collection from the database.\n",
    "collection = db[\"student_results\"]\n",
    "\n",
    "# We can retrieve the student node object in the json format from the collection by their id.\n",
    "student_info = collection.find({\"_id\": ObjectId(str(student_node.id))})[0]\n",
    "student_info.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:26:08.344764400Z",
     "start_time": "2023-12-12T15:26:08.189318200Z"
    }
   },
   "id": "2ccb58991b5d3f74"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's briefly explain the parameters and functions of the Recommender System:\n",
    "```\n",
    "def __init__(self,\n",
    "                 keyword_based: KeywordBased = None,\n",
    "                 bloom_based: BloomBased = None,\n",
    "                 explanation: LLM = None,\n",
    "                 warning_model: WarningModel = None,\n",
    "                 planner: UCMPlanner = None,\n",
    "                 validate_input: bool = True,\n",
    "                 top_n: int = 7,\n",
    "                 ):\n",
    "        self.validate_input = validate_input\n",
    "        self.keyword_based = keyword_based\n",
    "        self.bloom_based = bloom_based\n",
    "        self.explanation = explanation\n",
    "        self.warning_model = warning_model\n",
    "        self.planner = planner\n",
    "        self.top_n = top_n\n",
    "        self.db = pymongo.MongoClient(\"mongodb://localhost:27017/\")[\"RecSys\"]\n",
    "```\n",
    "- `keyword_based`: KeywordBased model.\n",
    "- `bloom_based`: BloomBased model.\n",
    "- `explanation`: LLM model.\n",
    "- `warning_model`: WarningModel model.\n",
    "- `planner`: UCMPlanner model.\n",
    "- `validate_input`: Boolean value. If True, the input from front-end will be validated.\n",
    "- `top_n`: Integer value. The number of courses that will be recommended in the period.  \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a411a0edf20b8ceb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "def validate_system_input(self,\n",
    "                              student_input,\n",
    "                              course_data,\n",
    "                              student_data,\n",
    "                              system_course_data,\n",
    "                              system_student_data):\n",
    "        \"\"\"\n",
    "        function: validate_system_input\n",
    "        description: validate the format of the input data\n",
    "        \"\"\"\n",
    "\n",
    "        check_student_input(student_input)\n",
    "\n",
    "        if system_student_data:\n",
    "            student_data = get_student_data()\n",
    "\n",
    "        if system_course_data:\n",
    "            exception_courses = []\n",
    "            if student_data:\n",
    "                exception_courses = list(student_data['courses_taken'].keys())\n",
    "            course_data = get_course_data(except_courses=exception_courses)\n",
    "\n",
    "        check_course_data(course_data)\n",
    "\n",
    "        if student_data is not None:\n",
    "            check_student_data(student_data)\n",
    "\n",
    "        return student_input, course_data, student_data\n",
    "```\n",
    "- function `validate_system_input`: Validate the format of the input data. If the input data is not in the correct format, it will raise an error. If the input data is in the correct format, it will return the input data. Additionally, we include system `course_data` and `student_data` in the input data if they are not provided by the front-end, but in later stage it should be provided by the front-end. All rules for the input data are defined in the `rec_sys_uni/error_checker/errors.py` file."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af354ec35bec1945"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_input does not have keywords\n"
     ]
    }
   ],
   "source": [
    "input = { # Lets make a mistake in the input data.\n",
    "    \"keyword\": { # Instead of keywords, we wrote keyword.\n",
    "        \"physics\": 1.0,\n",
    "        \"maths\": 1.0,\n",
    "        \"statistics\": 1.0,\n",
    "        \"ai\": 1.0,\n",
    "        \"computer science\": 1.0,\n",
    "        \"chem\": 1.0,\n",
    "    },\n",
    "    \"blooms\": {'create': 0.0,\n",
    "               'understand': 0.0,\n",
    "               'apply': 0.0,\n",
    "               'analyze': 0.0,\n",
    "               'evaluate': 0.0,\n",
    "               'remember': 0.0}\n",
    "}\n",
    "try:\n",
    "    student_node = rs.get_recommendation(input)\n",
    "except Exception as e:\n",
    "    print(e) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:26:10.044806300Z",
     "start_time": "2023-12-12T15:26:09.894790800Z"
    }
   },
   "id": "a33493c95e77f8fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "`get_recommendation` function is the main function of the system. It calls all the components of the system, which calculate recommendation and returns the `StudentNode` object. It takes the following parameters:\n",
    "```\n",
    "def get_recommendation(self,\n",
    "                           student_intput,\n",
    "                           course_data=None,\n",
    "                           student_data=None,\n",
    "                           system_course_data=True,\n",
    "                           system_student_data=False,\n",
    "                           ):\n",
    "        \"\"\"\n",
    "        function: get_recommendation\n",
    "        description: get Student Node object\n",
    "        \"\"\"\n",
    "\n",
    "        if self.validate_input:\n",
    "            student_input, course_data, student_data = self.validate_system_input(student_intput,\n",
    "                                                                                  course_data,\n",
    "                                                                                  student_data,\n",
    "                                                                                  system_course_data,\n",
    "                                                                                  system_student_data)\n",
    "\n",
    "        # Make results template\n",
    "        results = make_results_template(course_data)\n",
    "\n",
    "        # Create StudentNode object\n",
    "        student_info = StudentNode(results, student_intput, course_data, student_data)\n",
    "\n",
    "        # Compute recommendation and store in student_info\n",
    "        compute_recommendation(self, student_info)\n",
    "\n",
    "        # Compute warnings and store in student_info\n",
    "        if self.warning_model:\n",
    "            compute_warnings(self, student_info)\n",
    "\n",
    "        # Sort by periods\n",
    "        sort_by_periods(self, student_info, self.top_n, include_keywords=True, include_score=True,\n",
    "                        include_blooms=False)\n",
    "\n",
    "        # Save student_info to database\n",
    "        now = datetime.now()\n",
    "\n",
    "        collection = self.db[\"student_results\"]\n",
    "        input_dict = {\n",
    "            \"student_id\": \"123\",\n",
    "            \"student_input\": student_info.student_input,\n",
    "            \"course_data\": student_info.course_data,\n",
    "            \"student_data\": student_info.student_data,\n",
    "            \"results\": student_info.results,\n",
    "            \"time\": now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        }\n",
    "        object_db = collection.insert_one(input_dict)\n",
    "        student_info.set_id(object_db.inserted_id)\n",
    "\n",
    "        # Return StudentNode object\n",
    "        return student_info\n",
    "```\n",
    "- `student_input`: A dictionary that contains the student's input.\n",
    "- `course_data`: A dictionary that contains the course data.\n",
    "- `student_data`: A dictionary that contains the student's data.\n",
    "- `system_course_data`: Boolean value. If True, the system course data will be used.\n",
    "- `system_student_data`: Boolean value. If True, the system student data will be used.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "278561a135eb172"
  },
  {
   "cell_type": "markdown",
   "source": [
    "`generate_explanation` function is used to generate the explanation for the recommendation. It takes the following parameters:\n",
    "- `student_id`: A string representing the student's ID from MongoDB.\n",
    "- `course_code`: A string representing the course's code.\n",
    "\n",
    "`make_timeline` function is used to generate the timeline for the recommendation. It takes the following parameters:\n",
    "- `student_id`: A string representing the student's ID from MongoDB."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e49a97237739ecb4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Keyword Similarity:\n",
    "\n",
    "Our Keyword Similarity model is designed to assess the degree of similarity between a student's specified keywords and the content within course descriptions. To accomplish this, various models can be employed, particularly those available through the HuggingFace library, which is renowned for its diverse range of pre-trained models and natural language processing tools. These models from HuggingFace are adept at understanding and processing language, thus making them ideal for accurately gauging the relevance between keywords and course content.\n",
    "\n",
    "In addition to the options available in HuggingFace, there is also the possibility of utilizing an Intel-based model. This approach can be particularly advantageous when working with Intel server CPUs, as the model is optimized to efficiently compute embeddings on these processors. The use of an Intel model could potentially offer improved performance in terms of speed and efficiency, especially in environments that are already using Intel hardware.\n",
    "\n",
    "The choice between these models should be guided by several factors, including the specific requirements of the task, the available computational resources, and the desired balance between accuracy and efficiency. HuggingFace models might offer a wider range of capabilities and potentially higher accuracy due to their advanced algorithms and extensive training on diverse datasets. On the other hand, an Intel-optimized model might provide faster processing times and better integration with existing Intel server infrastructures, making it a practical choice for environments prioritizing efficiency and hardware compatibility.\n",
    "\n",
    "Ultimately, the decision on which model to use for computing keyword-course description similarity should be based on a thorough evaluation of the project's needs and the computational environment.\n",
    "\n",
    "Let's take a look at the `KeywordBased` class initialization:\n",
    "```\n",
    "# Keyword Based\n",
    "keyword_based = KeywordBased(model_name=\"all-MiniLM-L12-v2\",\n",
    "                             seed_help=True,\n",
    "                             domain_adapt=True,\n",
    "                             zero_adapt=True,\n",
    "                             domain_type='title',\n",
    "                             seed_type='title',\n",
    "                             zero_type='title',\n",
    "                             score_alg='sum',\n",
    "                             distance='cos',\n",
    "                             backend='keyBert',\n",
    "                             scaler=True,\n",
    "                             sent_splitter=False,\n",
    "                             precomputed_course=True)\n",
    "```\n",
    "\n",
    "- `model_name`: model name of the sentence transformer, specifically from the HuggingFace library.\n",
    "- `seed_help`: apply seed help, mix course description with seed words embeddings\n",
    "- `domain_adapt`: apply domain adaptation, add additional attention layer to the model\n",
    "- `zero_adapt`: apply zero-shot adaptation, more advance seed filtering\n",
    "- `seed_type`: type of the seed help either 'title' or 'domains', we use 'title' for now, since 'domains' did not show good performance\n",
    "- `domain_type`: type of the domain adaptation either 'title' or 'domains', we use 'title' for now, since 'domains' did not show good performance\n",
    "- `zero_type`: type of the zero-shot adaptation either 'title' or 'domains', we use 'title' for now, since 'domains' did not show good performance\n",
    "- `adaptive_thr`: adaptive threshold for the zero-shot adaptation\n",
    "- `minimal_similarity_zeroshot`: minimal similarity between a candidate and a domain word for the zero-shot adaptation\n",
    "- `score_alg`: score algorithm either 'sum' or 'rrf', currently we use 'sum', but Relevance Ranking Fusion (RRF) can be used, but with another implementation of keyword similarity\n",
    "- `distance`: distance metric either 'cos' or 'dot', for some models is required to use 'dot' instead of 'cos'.\n",
    "- `backend`: backend either 'keyBert' or 'Intel'. 'Intel' is used to compute the embeddings on Intel server CPU, but it provides only advance models like BGE, which can be too large for our system.\n",
    "- `scaler`: apply min-max scaler to the keywords weights.\n",
    "- `sent_splitter`: split the course description into sentences. It is implemented to use Linear Programing to calculate scores, but it still needs to be implemented.\n",
    "- `precomputed_course`: use precomputed course embeddings or not."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d888e037d625513"
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you are planning to use domain adaptation, zero-shot adaptation, or both, it is necessary to precompute the embeddings and the attention layer in advance. You can use the following code to precompute the embeddings and attention layer:\n",
    "\n",
    "```\n",
    "def calculate_zero_shot_adaptation(course_data, model_name, attention,\n",
    "                                   adaptive_thr: float = 0.15,\n",
    "                                   minimal_similarity_zeroshot: float = 0.8):\n",
    "```\n",
    "- `course_data`: A dictionary or list containing the course code. Please follow the template that we discussed earlier.\n",
    "- `model_name`: The name of the sentence transformer model, specifically from the HuggingFace library, for which you want to precompute the embedding for zero-shot adaptation.\n",
    "- `attention`: The specific words to which you want to apply attention in order to bring the embedding closer to the course domain within the embedding space.\n",
    "\n",
    "```\n",
    "def calculate_few_shot_adaptation(course_data, model_name, attention,\n",
    "                                  lr=1e-4, epochs=100,  # Training Parameters\n",
    "                                  start_index=0,\n",
    "                                  include_description=True,\n",
    "                                  include_title=False,\n",
    "                                  include_ilos=False, ):\n",
    "```\n",
    "- `course_data`: A dictionary containing course descriptions, Intended Learning Outcomes (ILOs), and the course code. Please follow the template that we discussed earlier.\n",
    "- `model_name`: The name of the sentence transformer model, specifically from the HuggingFace library, for which you want to precompute the embedding for few-shot adaptation.\n",
    "- `attention`: The specific words to which you want to apply attention in order to bring the embedding closer to the course domain within the embedding space.\n",
    "- `lr`: Learning rate.\n",
    "- `epochs`: Number of epochs.\n",
    "\n",
    "```\n",
    "def calculate_precomputed_courses(course_data, model_name,\n",
    "                                  include_description=True,\n",
    "                                  include_title=False,\n",
    "                                  include_ilos=False, ):\n",
    "```\n",
    "- `course_data`: A dictionary containing course descriptions, Intended Learning Outcomes (ILOs), and the course code. Please follow the template that we discussed earlier.\n",
    "- `model_name`: The name of the sentence transformer model, specifically from the HuggingFace library, for which you want to precompute the embedding for the course.\n",
    "- `include_description`: Boolean value. If True, the course description will be included in the embedding.\n",
    "- `include_title`: Boolean value. If True, the course title will be included in the embedding.\n",
    "- `include_ilos`: Boolean value. If True, the course ILOs will be included in the embedding.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51ec3738b748087d"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from rec_sys_uni.datasets.datasets import calculate_precomputed_courses, calculate_few_shot_adaptation, calculate_zero_shot_adaptation, get_course_data\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:26:12.900567300Z",
     "start_time": "2023-12-12T15:26:12.746550200Z"
    }
   },
   "id": "d7ca6c6042979bc5"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['COR1002', 'COR1003', 'COR1004', 'COR1006', 'HUM1003', 'HUM1007', 'HUM1010', 'HUM1011', 'HUM1012', 'HUM1013', 'HUM1016', 'HUM2003', 'HUM2005', 'HUM2007', 'HUM2008', 'HUM2013', 'HUM2016', 'HUM2018', 'HUM2021', 'HUM2022', 'HUM2030', 'HUM2031', 'HUM2046', 'HUM2047', 'HUM2051', 'HUM2054', 'HUM2056', 'HUM2057', 'HUM2058', 'HUM2059', 'HUM2060', 'HUM3014', 'HUM3019', 'HUM3029', 'HUM3034', 'HUM3036', 'HUM3040', 'HUM3042', 'HUM3043', 'HUM3044', 'HUM3045', 'HUM3049', 'HUM3050', 'HUM3051', 'HUM3052', 'HUM3053', 'SCI1004', 'SCI1005', 'SCI1009', 'SCI1010', 'SCI1016', 'SCI2002', 'SCI2009', 'SCI2010', 'SCI2011', 'SCI2017', 'SCI2018', 'SCI2019', 'SCI2022', 'SCI2031', 'SCI2033', 'SCI2034', 'SCI2035', 'SCI2036', 'SCI2037', 'SCI2039', 'SCI2040', 'SCI2041', 'SCI2042', 'SCI2043', 'SCI2044', 'SCI3003', 'SCI3005', 'SCI3006', 'SCI3007', 'SCI3046', 'SCI3049', 'SCI3050', 'SCI3051', 'SCI3052', 'SSC1005', 'SSC1007', 'SSC1025', 'SSC1027', 'SSC1029', 'SSC1030', 'SSC2002', 'SSC2004', 'SSC2006', 'SSC2007', 'SSC2008', 'SSC2009', 'SSC2010', 'SSC2011', 'SSC2018', 'SSC2019', 'SSC2020', 'SSC2022', 'SSC2024', 'SSC2025', 'SSC2027', 'SSC2028', 'SSC2029', 'SSC2037', 'SSC2039', 'SSC2043', 'SSC2046', 'SSC2048', 'SSC2050', 'SSC2053', 'SSC2055', 'SSC2060', 'SSC2061', 'SSC2062', 'SSC2063', 'SSC2064', 'SSC2065', 'SSC2070', 'SSC2071', 'SSC3002', 'SSC3003', 'SSC3006', 'SSC3008', 'SSC3009', 'SSC3011', 'SSC3012', 'SSC3013', 'SSC3017', 'SSC3018', 'SSC3019', 'SSC3023', 'SSC3030', 'SSC3032', 'SSC3033', 'SSC3034', 'SSC3036', 'SSC3038', 'SSC3040', 'SSC3041', 'SSC3047', 'SSC3049', 'SSC3051', 'SSC3052', 'SSC3054', 'SSC3055', 'SSC3056', 'SSC3059', 'SSC3060', 'SSC3061'])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_data = get_course_data()\n",
    "course_data.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:01:48.570549800Z",
     "start_time": "2023-12-12T15:01:48.429526700Z"
    }
   },
   "id": "9bdb34088a12aafc"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['course_name', 'period', 'level', 'prerequisites', 'description', 'ilos'])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_data['COR1002'].keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:01:49.545494800Z",
     "start_time": "2023-12-12T15:01:49.394456600Z"
    }
   },
   "id": "39e79c383a189aef"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate precomputed courses for the model: all-MiniLM-L12-v2\n",
      "System will calculate this list of courses: ['COR1002', 'COR1003', 'COR1004', 'COR1006', 'HUM1003', 'HUM1007', 'HUM1010', 'HUM1011', 'HUM1012', 'HUM1013', 'HUM1016', 'HUM2003', 'HUM2005', 'HUM2007', 'HUM2008', 'HUM2013', 'HUM2016', 'HUM2018', 'HUM2021', 'HUM2022', 'HUM2030', 'HUM2031', 'HUM2046', 'HUM2047', 'HUM2051', 'HUM2054', 'HUM2056', 'HUM2057', 'HUM2058', 'HUM2059', 'HUM2060', 'HUM3014', 'HUM3019', 'HUM3029', 'HUM3034', 'HUM3036', 'HUM3040', 'HUM3042', 'HUM3043', 'HUM3044', 'HUM3045', 'HUM3049', 'HUM3050', 'HUM3051', 'HUM3052', 'HUM3053', 'SCI1004', 'SCI1005', 'SCI1009', 'SCI1010', 'SCI1016', 'SCI2002', 'SCI2009', 'SCI2010', 'SCI2011', 'SCI2017', 'SCI2018', 'SCI2019', 'SCI2022', 'SCI2031', 'SCI2033', 'SCI2034', 'SCI2035', 'SCI2036', 'SCI2037', 'SCI2039', 'SCI2040', 'SCI2041', 'SCI2042', 'SCI2043', 'SCI2044', 'SCI3003', 'SCI3005', 'SCI3006', 'SCI3007', 'SCI3046', 'SCI3049', 'SCI3050', 'SCI3051', 'SCI3052', 'SSC1005', 'SSC1007', 'SSC1025', 'SSC1027', 'SSC1029', 'SSC1030', 'SSC2002', 'SSC2004', 'SSC2006', 'SSC2007', 'SSC2008', 'SSC2009', 'SSC2010', 'SSC2011', 'SSC2018', 'SSC2019', 'SSC2020', 'SSC2022', 'SSC2024', 'SSC2025', 'SSC2027', 'SSC2028', 'SSC2029', 'SSC2037', 'SSC2039', 'SSC2043', 'SSC2046', 'SSC2048', 'SSC2050', 'SSC2053', 'SSC2055', 'SSC2060', 'SSC2061', 'SSC2062', 'SSC2063', 'SSC2064', 'SSC2065', 'SSC2070', 'SSC2071', 'SSC3002', 'SSC3003', 'SSC3006', 'SSC3008', 'SSC3009', 'SSC3011', 'SSC3012', 'SSC3013', 'SSC3017', 'SSC3018', 'SSC3019', 'SSC3023', 'SSC3030', 'SSC3032', 'SSC3033', 'SSC3034', 'SSC3036', 'SSC3038', 'SSC3040', 'SSC3041', 'SSC3047', 'SSC3049', 'SSC3051', 'SSC3052', 'SSC3054', 'SSC3055', 'SSC3056', 'SSC3059', 'SSC3060', 'SSC3061']\n",
      "Check information above!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/149 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "070232eb044d40e8990fcd7ce27dc75c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calculate_precomputed_courses(course_data, \"all-MiniLM-L12-v2\"\n",
    "                              , include_description=True\n",
    "                              , include_title=True\n",
    "                              , include_ilos=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T22:50:34.108833800Z",
     "start_time": "2023-12-11T22:50:29.542865600Z"
    }
   },
   "id": "592c3fff26963567"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "149"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(course_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:01:52.763016400Z",
     "start_time": "2023-12-12T15:01:52.627994Z"
    }
   },
   "id": "faf70cc64ea5fcdd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "attention = {}\n",
    "for i in course_data.keys():\n",
    "    attention[i] = course_data[i]['course_name']\n",
    "calculate_few_shot_adaptation(course_data, \"all-MiniLM-L12-v2\", attention=attention, use_cuda=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "961227cfb8f97c8d"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate Zero-Shot Adaptation based on course title for the model: all-MiniLM-L12-v2\n",
      "System will calculate this list of courses: ['COR1002', 'COR1003', 'COR1004', 'COR1006', 'HUM1003', 'HUM1007', 'HUM1010', 'HUM1011', 'HUM1012', 'HUM1013', 'HUM1016', 'HUM2003', 'HUM2005', 'HUM2007', 'HUM2008', 'HUM2013', 'HUM2016', 'HUM2018', 'HUM2021', 'HUM2022', 'HUM2030', 'HUM2031', 'HUM2046', 'HUM2047', 'HUM2051', 'HUM2054', 'HUM2056', 'HUM2057', 'HUM2058', 'HUM2059', 'HUM2060', 'HUM3014', 'HUM3019', 'HUM3029', 'HUM3034', 'HUM3036', 'HUM3040', 'HUM3042', 'HUM3043', 'HUM3044', 'HUM3045', 'HUM3049', 'HUM3050', 'HUM3051', 'HUM3052', 'HUM3053', 'SCI1004', 'SCI1005', 'SCI1009', 'SCI1010', 'SCI1016', 'SCI2002', 'SCI2009', 'SCI2010', 'SCI2011', 'SCI2017', 'SCI2018', 'SCI2019', 'SCI2022', 'SCI2031', 'SCI2033', 'SCI2034', 'SCI2035', 'SCI2036', 'SCI2037', 'SCI2039', 'SCI2040', 'SCI2041', 'SCI2042', 'SCI2043', 'SCI2044', 'SCI3003', 'SCI3005', 'SCI3006', 'SCI3007', 'SCI3046', 'SCI3049', 'SCI3050', 'SCI3051', 'SCI3052', 'SSC1005', 'SSC1007', 'SSC1025', 'SSC1027', 'SSC1029', 'SSC1030', 'SSC2002', 'SSC2004', 'SSC2006', 'SSC2007', 'SSC2008', 'SSC2009', 'SSC2010', 'SSC2011', 'SSC2018', 'SSC2019', 'SSC2020', 'SSC2022', 'SSC2024', 'SSC2025', 'SSC2027', 'SSC2028', 'SSC2029', 'SSC2037', 'SSC2039', 'SSC2043', 'SSC2046', 'SSC2048', 'SSC2050', 'SSC2053', 'SSC2055', 'SSC2060', 'SSC2061', 'SSC2062', 'SSC2063', 'SSC2064', 'SSC2065', 'SSC2070', 'SSC2071', 'SSC3002', 'SSC3003', 'SSC3006', 'SSC3008', 'SSC3009', 'SSC3011', 'SSC3012', 'SSC3013', 'SSC3017', 'SSC3018', 'SSC3019', 'SSC3023', 'SSC3030', 'SSC3032', 'SSC3033', 'SSC3034', 'SSC3036', 'SSC3038', 'SSC3040', 'SSC3041', 'SSC3047', 'SSC3049', 'SSC3051', 'SSC3052', 'SSC3054', 'SSC3055', 'SSC3056', 'SSC3059', 'SSC3060', 'SSC3061']\n",
      "Check information above!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/149 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15b9ebbcd33943bd9d64e814d0a39859"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calculate_zero_shot_adaptation(course_data, \"all-MiniLM-L12-v2\", attention=attention)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:24:11.559928300Z",
     "start_time": "2023-12-12T15:08:53.220818500Z"
    }
   },
   "id": "adbd4a700520cbe0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can find additional information about attention-based keyword similarity [here](https://arxiv.org/pdf/2211.07499.pdf). \n",
    "\n",
    "If you follow all the steps outlined above, you will be able to use the new model to compute the similarity between the student's keywords and the course descriptions. Note that all embeddings and layers will be downloaded automatically; just remember to change the model during the initialization of KeywordBased"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af350af8587dda92"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bloom's Taxonomy:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e69af0af2677299"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T20:54:24.911303100Z",
     "start_time": "2023-12-10T20:54:24.895289800Z"
    }
   },
   "id": "a9bfa336c09f2734"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Explanation with Generative LLM:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44e3dc7189609d6f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Currently, we are utilizing OpenAI's technology to provide explanations for keywords and to summarize course descriptions. This is achieved through a combination of a prompt template and few-shot learning examples, as implemented in our `rec_sys_uni/rec_systems/llm_explanation/LLM.py` script. One significant advantage of using OpenAI is its capability to generate outputs in JSON format, which facilitates easier integration and manipulation of data in various applications.\n",
    "\n",
    "However, we are contemplating the development and deployment of our proprietary model for generating explanations. The primary motivation behind this shift is the potential for greater customization and accuracy. By fine-tuning our model specifically to our dataset, we aim to achieve performance that surpasses what we currently obtain with OpenAI. Own model will allow for more tailored and precise explanations, catering specifically to the unique characteristics and requirements of our data.\n",
    "\n",
    "Furthermore, developing our model could offer additional benefits such as enhanced control over the model's behavior, the ability to continuously improve and adapt the model based on incoming data and feedback, and potentially lower long-term costs associated with using a third-party service. While the initial development and training might require significant resources, the long-term benefits could be substantial, especially in terms of offering a more personalized and relevant user experience."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36018857aceadc00"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# To get the explanation for the course, we need to provide the student id and course code.\n",
    "explanation = rs.generate_explanation(student_node.id, \"SCI2039\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:58:27.244866700Z",
     "start_time": "2023-12-12T15:58:16.543312800Z"
    }
   },
   "id": "48f7136335bd12d5"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['course_code', 'course_title', 'summary_description', 'keywords_explanation'])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T15:58:29.759187100Z",
     "start_time": "2023-12-12T15:58:29.605035400Z"
    }
   },
   "id": "7e67b790db9e6ad9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Course Overview\n",
    "\n",
    "## SCI2039: Computer Science\n",
    "\n",
    "### Summary Description\n",
    "Computer Science is a comprehensive course that provides an overview of the discipline, covering a wide range of topics including algorithmic foundations of informatics, hardware issues, such as number systems and computer architectures, and software issues, such as operating systems, programming languages, compilers, networks, the Internet, and artificial intelligence. The course also includes practical lab sessions to investigate the concepts introduced. By the end of the course, students are expected to have developed experience in applying techniques from informatics, computer science, and programming for their own research and educational purposes.\n",
    "\n",
    "### Relevance to Other Disciplines\n",
    "\n",
    "- **Physics**\n",
    "  - While there is a moderate similarity between physics and the course description (keyword similarity: 0.9), the course does not directly cover physics topics. However, the analytical and problem-solving skills developed in physics can be beneficial in computer science.\n",
    "\n",
    "- **Maths**\n",
    "  - Mathematics is highly relevant to this course (keyword similarity: 0.67), as it forms the foundation of many computer science concepts, such as algorithms, logic, and discrete mathematics.\n",
    "\n",
    "- **Statistics**\n",
    "  - Statistics has some relevance to the course (keyword similarity: 0.28), particularly in the context of data analysis and interpretation, which are essential in computer science.\n",
    "\n",
    "- **AI**\n",
    "  - Artificial intelligence is directly relevant to the course (keyword similarity: 0.51), as it is explicitly mentioned in the course description. The course covers artificial intelligence as one of the key topics.\n",
    "\n",
    "- **Computer Science**\n",
    "  - The course is directly aligned with computer science (keyword similarity: 1.0), as it is the main subject of the course title. The course covers a broad range of computer science topics, providing a comprehensive introduction to the field.\n",
    "\n",
    "- **Chem**\n",
    "  - While there is a moderate similarity between chemistry and the course description (keyword similarity: 0.57), the course does not directly cover chemistry topics. However, the analytical and logical thinking skills developed in chemistry can be beneficial in computer science.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fe4d50ae6fd11be"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Planner (Integer Linear Programming):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fdc91686139a981"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T20:54:24.942353600Z",
     "start_time": "2023-12-10T20:54:24.926329100Z"
    }
   },
   "id": "3ff55a484e91a434"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Warning System:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ddd9a3a17ff5a09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "At present, our warning system is facing challenges in achieving accurate predictions due to imbalanced student data. This imbalance adversely affects the system's ability to correctly predict instances of academic failure. To address this issue, a more refined approach is being considered. We propose to define common features across courses, focusing on key skills such as physics, mathematics, law, etc. By identifying and utilizing these skill-based features, we aim to improve the prediction accuracy of potential academic failures. Furthermore, this approach will enable us to provide students with tailored recommendations on which courses to undertake in order to develop the relevant skills needed to succeed in courses they are predicted to struggle with.\n",
    "\n",
    "Previously, we experimented with using embeddings, assigning weights based on students' grades. However, this method resulted in overly generalized embeddings, leading to indistinct differentiation between them. \n",
    "\n",
    "Currently, we are now employing a Random Forest Classifier to predict academic failures. This classifier offers the advantage of feature importance analysis, which we utilize to determine the key aspects contributing to potential failures or passing. Additionally, we leverage the capabilities of a Sentence Transformer to check these potential courses and give warning recommendations with the matching score with the predicted course."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47b92b198a50f26e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Warning model implementation and usage: you can find the warning model in the `rec_sys_uni/rec_systems/warning_model/warning_model.py` script and `notebooks/Warning_Model.ipynb` notebook. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53d9f90c7daa2f63"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collaborative Filtering:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28da1aa787914172"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We implemented a matrix factorization method to generate course recommendations, utilizing student data that includes academic grades. However, this system is not yet fully integrated, as it requires access to real student IDs from Maastricht University. Additionally, the model necessitates periodic updates to maintain its relevance and accuracy.\n",
    "\n",
    "A significant challenge we face with this approach is the limited number of courses taken by individual students. This situation leads to a sparse matrix, which complicates the recommendation process. Sparse data can significantly hinder the effectiveness of matrix factorization techniques, as these methods rely on a denser dataset to make accurate predictions and recommendations.\n",
    "\n",
    "To address this issue, we are exploring alternative methods. One promising approach is the use of a Knowledge Graph. This method can effectively leverage the available student data to provide course recommendations. A Knowledge Graph, by its very nature, is adept at handling sparse data. It creates a network of entities (such as students, courses, skills) and their interrelations, allowing for a more nuanced understanding of student profiles and course attributes. This enhanced understanding can lead to more accurate and personalized course recommendations, even when dealing with limited student course histories.\n",
    "\n",
    "By incorporating a Knowledge Graph, we aim to overcome the limitations posed by sparse data and improve the overall effectiveness of our recommendation system. This approach not only promises to deliver better-tailored course suggestions to students but also has the potential to evolve and scale as more data becomes available or as the educational offerings at Maastricht University expand and change."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bdce2ed5dda1e24"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Collaborative Filtering implementation: you can find the collaborative filtering model in the `notebooks/Collaborative_Filtering.ipynb` notebook."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d21687e5daee8f24"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Knowledge Graph:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e0ca8f476123ea4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1e7b138c58bc2ef8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "acd4208aede71543"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ab0be78e420e8a0d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cf6fb378ed711158"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
